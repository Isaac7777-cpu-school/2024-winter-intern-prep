<!DOCTYPE html>
<html>
<head>
<title>transformer_lit_note.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<!-- MathJax Configuration -->
<script>
	window.MathJax = {
		tex: {
		inlineMath: [['$', '$'], ['\\(', '\\)']],
		displayMath: [['$$', '$$'], ['\\[', '\\]']]
		},
		svg: {
		fontCache: 'global'
		}
	};
</script>
	
<!-- MathJax Script -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="abstract">Abstract</h1>
<ul>
<li>BLEU score =&gt; a metrics for measuring documents translation</li>
<li>Did not use RNN nor CNN but solely based on attention mechanism</li>
</ul>
<h1 id="introduction">Introduction</h1>
<ul>
<li>First just talks about RNN, LSTM, CNN...</li>
<li>Note that LSTM is much harder to parallel due to its sequential thing</li>
<li>Attention was used before for delivering content from encoder to decoder.</li>
<li>Attention based can be purely parallel</li>
</ul>
<h1 id="background">Background</h1>
<ul>
<li>Using RNN =&gt; Harder to relate distanced information</li>
<li>Attention can read the whole line at once</li>
<li>In order to achieve multiple channels output like RNN, they have proposed a Multi-Head Attention mechanism</li>
<li>Self-attention is also mentioned</li>
</ul>
<h1 id="model-architecture">Model Architecture</h1>
<ul>
<li>Good models are basically encoder-decoder structure</li>
<li>Are the connections from encoder to the decoder's multihead is duplicated</li>
</ul>
<h2 id="attention">Attention</h2>
<h3 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h3>
<ul>
<li>What are queries ($Q$), keys($K$) and values($V$)?
<ul>
<li>They are packed queries, keys, and values</li>
<li>$Q$ should be row major, and then $QK^T$ is like a dot-product for each element</li>
<li>Note that both queries and keys are of dimension $d_k$</li>
<li><a href="https://www.linkedin.com/pulse/all-query-key-values-transformer-anjil-adhikari-1vrif/">An explanation to what are query, key, and values</a></li>
</ul>
</li>
</ul>
<h3 id="multi-head-attention">Multi-Head Attention</h3>
<p>$$
\text{MultiHead}(Q,K,V) = \text{Concat(}\text{head}<em>1, \ldots, \text{head}</em>\text{h})W^O \
\textbf{where } \text{head}_\text{i} = \text{Attention}(QW^Q_i, KW^K_i, VW^V_i)
$$</p>
<p>where the projections are parameter matrices $W^Q_i, W^K_i \in \mathbf{R}^{d_\text{model}\times d_k}$, $W^V_i, \in \mathbf{R}^{d_\text{model}\times d_v}$</p>
<p>Note that $d_\text{model}$ is the dimension of keys, values, and queries (in the original settings).</p>
<h3 id="applications-of-attention-in-our-model">Applications of Attention in our Model</h3>
<ul>
<li>In &quot;encoder-decoder atention&quot; layers, the queries come from the previous decoder layer and the memory keys and values come from the output of the encoder.</li>
<li>The encooder contains self-attention layers</li>
<li>The decoder also contains self-attention layers</li>
</ul>
<h2 id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</h2>
<p>$$
\text{FFN}(x) = \text{max}(0, xW_1 + b_1)W_2 + b_2
$$</p>
<p>This is appended to all the outputs of the encoder and decoder attention cel</p>
<h2 id="embeddings-and-softmax">Embeddings and Softmax</h2>
<ul>
<li>The model learns embeddings to convert the input tokens and output tokes to vectors of dimenson $d_{\text{model}}$.</li>
<li>Also use linear transformation and softmax function to convert the decoder output to predicted next-token probabilities.</li>
</ul>
<h2 id="positional-encoding">Positional Encoding</h2>
<ul>
<li>Since the model containes no recurrence and no convolution, in order for the model to make use of the order of the sequence, they have injected some information about the relative or abslte position of the tokens in the sequence.</li>
<li>Hence, &quot;positional encodings&quot; are added to the input embeddings at the bottoms of the encoder and decoder stacks.</li>
</ul>
<h1 id="why-self-attention">Why Self-Attention</h1>
<ul>
<li>Self-attention mechanism can allow very long distance dependency</li>
<li>It also requires much less complexity than traditional CNN and RNN</li>
</ul>
<h1 id="training">Training</h1>
<h1 id="conclusion">Conclusion</h1>
<ul>
<li>Just Better!</li>
</ul>

</body>
</html>
